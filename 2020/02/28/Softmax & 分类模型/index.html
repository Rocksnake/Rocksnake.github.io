<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
<meta name="viewport"
      content="width=device-width, initial-scale=1.0, maximum-scale=1.0, minimum-scale=1.0">
<meta http-equiv="X-UA-Compatible" content="ie=edge">

    <meta name="author" content="Rokosnake">





<title>Softmax &amp; 分类模型 | RokoBasilisk&#39;s Blog</title>



    <link rel="icon" href="/favicon.ico">




    <!-- stylesheets list from _config.yml -->
    
    <link rel="stylesheet" href="/css/style.css">
    



    <!-- scripts list from _config.yml -->
    
    <script src="/js/script.js"></script>
    
    <script src="/js/tocbot.min.js"></script>
    



    
    
        <!-- MathJax配置，可通过单美元符号书写行内公式等 -->
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
    "HTML-CSS": {
        preferredFont: "TeX",
        availableFonts: ["STIX","TeX"],
        linebreaks: { automatic:true },
        EqnChunk: (MathJax.Hub.Browser.isMobile ? 10 : 50)
    },
    tex2jax: {
        inlineMath: [ ["$", "$"], ["\\(","\\)"] ],
        processEscapes: true,
        ignoreClass: "tex2jax_ignore|dno",
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    },
    TeX: {
        equationNumbers: { autoNumber: "AMS" },
        noUndefined: { attributes: { mathcolor: "red", mathbackground: "#FFEEEE", mathsize: "90%" } },
        Macros: { href: "{}" }
    },
    messageStyle: "none"
    });
</script>
<!-- 给MathJax元素添加has-jax class -->
<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>
<!-- 通过连接CDN加载MathJax的js代码 -->
<script type="text/javascript" async
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML">
</script>


    


<meta name="generator" content="Hexo 4.2.0"><link rel="alternate" href="/atom.xml" title="RokoBasilisk's Blog" type="application/atom+xml">
</head>
<body>
    <div class="wrapper">
        <header>
    <nav class="navbar">
        <div class="container">
            <div class="navbar-header header-logo"><a href="/">RokoのBasilisk&#39;s Blog</a></div>
            <div class="menu navbar-right">
                
                    <a class="menu-item" href="/archives">Posts</a>
                
                    <a class="menu-item" href="/category">Categories</a>
                
                    <a class="menu-item" href="/tag">Tags</a>
                
                    <a class="menu-item" href="/about">About</a>
                
                <input id="switch_default" type="checkbox" class="switch_default">
                <label for="switch_default" class="toggleBtn"></label>
            </div>
        </div>
    </nav>

    
    <nav class="navbar-mobile" id="nav-mobile">
        <div class="container">
            <div class="navbar-header">
                <div>
                    <a href="/">RokoのBasilisk&#39;s Blog</a><a id="mobile-toggle-theme">·&nbsp;Light</a>
                </div>
                <div class="menu-toggle" onclick="mobileBtn()">&#9776; Menu</div>
            </div>
            <div class="menu" id="mobile-menu">
                
                    <a class="menu-item" href="/archives">Posts</a>
                
                    <a class="menu-item" href="/category">Categories</a>
                
                    <a class="menu-item" href="/tag">Tags</a>
                
                    <a class="menu-item" href="/about">About</a>
                
            </div>
        </div>
    </nav>

</header>
<script>
    var mobileBtn = function f() {
        var toggleMenu = document.getElementsByClassName("menu-toggle")[0];
        var mobileMenu = document.getElementById("mobile-menu");
        if(toggleMenu.classList.contains("active")){
           toggleMenu.classList.remove("active")
            mobileMenu.classList.remove("active")
        }else{
            toggleMenu.classList.add("active")
            mobileMenu.classList.add("active")
        }
    }
</script>
        <div class="main">
            <div class="container">
    
    
        <div class="post-toc">
    <div class="tocbot-list">
    </div>
    <div class="tocbot-list-menu">
        <a class="tocbot-toc-expand" onclick="expand_toc()">Expand all</a>
        <a onclick="go_top()">Back to top</a>
        <a onclick="go_bottom()">Go to bottom</a>
    </div>
</div>

<script>
    document.ready(
        function () {
            tocbot.init({
                tocSelector: '.tocbot-list',
                contentSelector: '.post-content',
                headingSelector: 'h1, h2, h3, h4, h5',
                collapseDepth: 1,
                orderedList: false,
                scrollSmooth: true,
            })
        }
    )

    function expand_toc() {
        var b = document.querySelector(".tocbot-toc-expand");
        tocbot.init({
            tocSelector: '.tocbot-list',
            contentSelector: '.post-content',
            headingSelector: 'h1, h2, h3, h4, h5',
            collapseDepth: 6,
            orderedList: false,
            scrollSmooth: true,
        });
        b.setAttribute("onclick", "collapse_toc()");
        b.innerHTML = "Collapse all"
    }

    function collapse_toc() {
        var b = document.querySelector(".tocbot-toc-expand");
        tocbot.init({
            tocSelector: '.tocbot-list',
            contentSelector: '.post-content',
            headingSelector: 'h1, h2, h3, h4, h5',
            collapseDepth: 1,
            orderedList: false,
            scrollSmooth: true,
        });
        b.setAttribute("onclick", "expand_toc()");
        b.innerHTML = "Expand all"
    }

    function go_top() {
        window.scrollTo(0, 0);
    }

    function go_bottom() {
        window.scrollTo(0, document.body.scrollHeight);
    }

</script>
    

    
    <article class="post-wrap">
        <header class="post-header">
            <h1 class="post-title">Softmax &amp; 分类模型</h1>
            
                <div class="post-meta">
                    
                        Author: <a itemprop="author" rel="author" href="/">Rokosnake</a>
                    

                    
                        <span class="post-time">
                        Date: <a href="#">February 28, 2020&nbsp;&nbsp;9:57:30</a>
                        </span>
                    
                    
                        <span class="post-category">
                    Category:
                            
                                <a href="/categories/Machine-Learning/">Machine Learning</a>
                            
                        </span>
                    
                </div>
            
        </header>

        <div class="post-content">
            <h1 id="Softmax"><a href="#Softmax" class="headerlink" title="Softmax"></a>Softmax</h1><blockquote>
<p>与候选采样相对</p>
</blockquote>
<p>Softmax function, a wonderful activation function that turns numbers aka logits into probabilities that sum to one. Softmax function outputs a vector that represents the probability distributions of a list of potential outcomes.</p>
<p>一种函数，可提供多类别分类模型中每个可能类别的概率。这些概率的总和正好为 1.0。</p>
<p>Example: softmax 可能会得出某个图像是狗、猫和马的概率分别是 0.9、0.08 和 0.02。（也称为完整 softmax。）<img src="https://img-blog.csdnimg.cn/20200212195050635.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1Jva29CYXNpbGlzaw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<h2 id="softmax的基本概念"><a href="#softmax的基本概念" class="headerlink" title="softmax的基本概念"></a>softmax的基本概念</h2><ul>
<li><p>分类问题<br>一个简单的图像分类问题，输入图像的高和宽均为2像素，色彩为灰度。<br>图像中的4像素分别记为$x_1, x_2, x_3, x_4$。<br>假设真实标签为狗、猫或者鸡，这些标签对应的离散值为$y_1, y_2, y_3$。<br>我们通常使用离散的数值来表示类别，例如$y_1=1, y_2=2, y_3=3$。</p>
</li>
<li><p>权重矢量  </p>
</li>
</ul>
<p>$$<br> \begin{aligned} o_1 &amp;= x_1 w_{11} + x_2 w_{21} + x_3 w_{31} + x_4 w_{41} + b_1 \end{aligned}<br>$$</p>
<p>$$<br> \begin{aligned} o_2 &amp;= x_1 w_{12} + x_2 w_{22} + x_3 w_{32} + x_4 w_{42} + b_2 \end{aligned}<br>$$</p>
<p>$$<br> \begin{aligned} o_3 &amp;= x_1 w_{13} + x_2 w_{23} + x_3 w_{33} + x_4 w_{43} + b_3 \end{aligned}<br>$$</p>
<ul>
<li>神经网络图<br>下图用神经网络图描绘了上面的计算。softmax回归同线性回归一样，也是一个单层神经网络。由于每个输出$o_1, o_2, o_3$的计算都要依赖于所有的输入$x_1, x_2, x_3, x_4$，softmax回归的输出层也是一个全连接层。</li>
</ul>
<div align=center><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9jZG4ua2VzY2kuY29tL3VwbG9hZC9pbWFnZS9xNWhteW1lem9nLnBuZw?x-oss-process=image/format,png" /></div> 

<p>$$<br>\begin{aligned}softmax回归是一个单层神经网络\end{aligned}<br>$$</p>
<p>既然分类问题需要得到离散的预测输出，一个简单的办法是将输出值$o_i$当作预测类别是$i$的置信度，并将值最大的输出所对应的类作为预测输出，即输出 $\underset{i}{\arg\max} o_i$。例如，如果$o_1,o_2,o_3$分别为$0.1,10,0.1$，由于$o_2$最大，那么预测类别为2，其代表猫。</p>
<ul>
<li>输出问题<br>直接使用输出层的输出有两个问题：<ol>
<li>一方面，由于输出层的输出值的范围不确定，我们难以直观上判断这些值的意义。例如，刚才举的例子中的输出值10表示“很置信”图像类别为猫，因为该输出值是其他两类的输出值的100倍。但如果$o_1=o_3=10^3$，那么输出值10却又表示图像类别为猫的概率很低。</li>
<li>另一方面，由于真实标签是离散值，这些离散值与不确定范围的输出值之间的误差难以衡量。</li>
</ol>
</li>
</ul>
<p>softmax运算符（softmax operator）解决了以上两个问题。它通过下式将输出值变换成值为正且和为1的概率分布：</p>
<p>$$<br> \hat{y}_1, \hat{y}_2, \hat{y}_3 = \text{softmax}(o_1, o_2, o_3)<br>$$</p>
<p>其中</p>
<p>$$<br> \hat{y}1 = \frac{ \exp(o_1)}{\sum_{i=1}^3 \exp(o_i)},\quad \hat{y}2 = \frac{ \exp(o_2)}{\sum_{i=1}^3 \exp(o_i)},\quad \hat{y}3 = \frac{ \exp(o_3)}{\sum_{i=1}^3 \exp(o_i)}.<br>$$</p>
<p>容易看出$\hat{y}_1 + \hat{y}_2 + \hat{y}_3 = 1$且$0 \leq \hat{y}_1, \hat{y}_2, \hat{y}_3 \leq 1$，因此$\hat{y}_1, \hat{y}_2, \hat{y}_3$是一个合法的概率分布。这时候，如果$\hat{y}_2=0.8$，不管$\hat{y}_1$和$\hat{y}_3$的值是多少，我们都知道图像类别为猫的概率是80%。此外，我们注意到</p>
<p>$$<br> \underset{i}{\arg\max} o_i = \underset{i}{\arg\max} \hat{y}_i<br>$$</p>
<p>因此softmax运算不改变预测类别输出。</p>
<ul>
<li>计算效率<ul>
<li>单样本矢量计算表达式<br>为了提高计算效率，我们可以将单样本分类通过矢量计算来表达。在上面的图像分类问题中，假设softmax回归的权重和偏差参数分别为</li>
</ul>
</li>
</ul>
<p>$$<br> \boldsymbol{W} = \begin{bmatrix} w_{11} &amp; w_{12} &amp; w_{13} \ w_{21} &amp; w_{22} &amp; w_{23} \ w_{31} &amp; w_{32} &amp; w_{33} \ w_{41} &amp; w_{42} &amp; w_{43} \end{bmatrix},\quad \boldsymbol{b} = \begin{bmatrix} b_1 &amp; b_2 &amp; b_3 \end{bmatrix},<br>$$</p>
<p>设高和宽分别为2个像素的图像样本$i$的特征为</p>
<p>$$<br>\boldsymbol{x}^{(i)} = \begin{bmatrix}x_1^{(i)} &amp; x_2^{(i)} &amp; x_3^{(i)} &amp; x_4^{(i)}\end{bmatrix},<br>$$</p>
<p>输出层的输出为</p>
<p>$$<br>\boldsymbol{o}^{(i)} = \begin{bmatrix}o_1^{(i)} &amp; o_2^{(i)} &amp; o_3^{(i)}\end{bmatrix},<br>$$</p>
<p>预测为狗、猫或鸡的概率分布为</p>
<p>$$<br>\boldsymbol{\hat{y}}^{(i)} = \begin{bmatrix}\hat{y}_1^{(i)} &amp; \hat{y}_2^{(i)} &amp; \hat{y}_3^{(i)}\end{bmatrix}.<br>$$</p>
<p>softmax回归对样本$i$分类的矢量计算表达式为</p>
<p>$$<br> \begin{aligned} \boldsymbol{o}^{(i)} &amp;= \boldsymbol{x}^{(i)} \boldsymbol{W} + \boldsymbol{b},\ \boldsymbol{\hat{y}}^{(i)} &amp;= \text{softmax}(\boldsymbol{o}^{(i)}). \end{aligned}<br>$$</p>
<ul>
<li>小批量矢量计算表达式<br>  为了进一步提升计算效率，我们通常对小批量数据做矢量计算。广义上讲，给定一个小批量样本，其批量大小为$n$，输入个数（特征数）为$d$，输出个数（类别数）为$q$。设批量特征为$\boldsymbol{X} \in \mathbb{R}^{n \times d}$。假设softmax回归的权重和偏差参数分别为$\boldsymbol{W} \in \mathbb{R}^{d \times q}$和$\boldsymbol{b} \in \mathbb{R}^{1 \times q}$。softmax回归的矢量计算表达式为</li>
</ul>
<p>$$<br> \begin{aligned} \boldsymbol{O} &amp;= \boldsymbol{X} \boldsymbol{W} + \boldsymbol{b},\ \boldsymbol{\hat{Y}} &amp;= \text{softmax}(\boldsymbol{O}), \end{aligned}<br>$$</p>
<p>其中的加法运算使用了广播机制，$\boldsymbol{O}, \boldsymbol{\hat{Y}} \in \mathbb{R}^{n \times q}$且这两个矩阵的第$i$行分别为样本$i$的输出$\boldsymbol{o}^{(i)}$和概率分布$\boldsymbol{\hat{y}}^{(i)}$。</p>
<hr>
<p>两种操作对比</p>
<blockquote>
<p>numpy 操作：np.exp(x) / np.sum(np.exp(x), axis=0)<br>pytorch 操作：torch.exp(x)/torch.sum(torch.exp(x), dim=1).view(-1,1)</p>
</blockquote>
<h2 id="引入Fashion-MNIST"><a href="#引入Fashion-MNIST" class="headerlink" title="引入Fashion-MNIST"></a>引入Fashion-MNIST</h2><blockquote>
<p>为方便介绍 Softmax， 为了更加直观的观察到算法之间的差异<br>引入较为复杂的多分类图像分类数据集</p>
<blockquote>
<p>导入：torchvision 包【构建计算机视觉模型】</p>
</blockquote>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># import needed package</span></span><br><span class="line">%matplotlib inline</span><br><span class="line"><span class="keyword">from</span> IPython <span class="keyword">import</span> display</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">import</span> torchvision.transforms <span class="keyword">as</span> transforms</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line">sys.path.append(<span class="string">"path to file storge d2lzh1981"</span>)</span><br><span class="line"><span class="keyword">import</span> d2lzh1981 <span class="keyword">as</span> d2l</span><br><span class="line"></span><br><span class="line"><span class="comment"># print(torch.__version__)</span></span><br><span class="line"><span class="comment"># print(torchvision.__version__)</span></span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># get dataset</span></span><br><span class="line">mnist_train = torchvision.datasets.FashionMNIST(root=<span class="string">'path to file storge FashionMNIST.zip'</span>, train=<span class="literal">True</span>, download=<span class="literal">True</span>, transform=transforms.ToTensor())</span><br><span class="line">mnist_test = torchvision.datasets.FashionMNIST(root=<span class="string">'path to file storge FashionMNIST.zip'</span>, train=<span class="literal">False</span>, download=<span class="literal">True</span>, transform=transforms.ToTensor())</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_fashion_mnist_labels</span><span class="params">(labels)</span>:</span></span><br><span class="line">    text_labels = [<span class="string">'t-shirt'</span>, <span class="string">'trouser'</span>, <span class="string">'pullover'</span>, <span class="string">'dress'</span>, <span class="string">'coat'</span>,</span><br><span class="line">                   <span class="string">'sandal'</span>, <span class="string">'shirt'</span>, <span class="string">'sneaker'</span>, <span class="string">'bag'</span>, <span class="string">'ankle boot'</span>]</span><br><span class="line">    <span class="keyword">return</span> [text_labels[int(i)] <span class="keyword">for</span> i <span class="keyword">in</span> labels]</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">show_fashion_mnist</span><span class="params">(images, labels)</span>:</span></span><br><span class="line">    d2l.use_svg_display()</span><br><span class="line">    <span class="comment"># 这里的_表示我们忽略（不使用）的变量</span></span><br><span class="line">    _, figs = plt.subplots(<span class="number">1</span>, len(images), figsize=(<span class="number">12</span>, <span class="number">12</span>))</span><br><span class="line">    <span class="keyword">for</span> f, img, lbl <span class="keyword">in</span> zip(figs, images, labels):</span><br><span class="line">        f.imshow(img.view((<span class="number">28</span>, <span class="number">28</span>)).numpy())</span><br><span class="line">        f.set_title(lbl)</span><br><span class="line">        f.axes.get_xaxis().set_visible(<span class="literal">False</span>)</span><br><span class="line">        f.axes.get_yaxis().set_visible(<span class="literal">False</span>)</span><br><span class="line">    plt.show()</span><br><span class="line">X, y = [], []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">10</span>):</span><br><span class="line">    X.append(mnist_train[i][<span class="number">0</span>]) <span class="comment"># 将第i个feature加到X中</span></span><br><span class="line">    y.append(mnist_train[i][<span class="number">1</span>]) <span class="comment"># 将第i个label加到y中</span></span><br><span class="line">show_fashion_mnist(X, get_fashion_mnist_labels(y))</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># read data</span></span><br><span class="line">batch_size = <span class="number">256</span></span><br><span class="line">num_workers = <span class="number">4</span></span><br><span class="line">train_iter = torch.utils.data.DataLoader(mnist_train, batch_size=batch_size, shuffle=<span class="literal">True</span>, num_workers=num_workers)</span><br><span class="line">test_iter = torch.utils.data.DataLoader(mnist_test, batch_size=batch_size, shuffle=<span class="literal">False</span>, num_workers=num_workers)</span><br><span class="line"></span><br><span class="line">start = time.time()</span><br><span class="line"><span class="keyword">for</span> X, y <span class="keyword">in</span> train_iter:</span><br><span class="line">    <span class="keyword">continue</span></span><br><span class="line">print(<span class="string">'%.2f sec'</span> % (time.time() - start))</span><br></pre></td></tr></table></figure>

<h2 id="Softmax-手动实现"><a href="#Softmax-手动实现" class="headerlink" title="Softmax 手动实现"></a>Softmax 手动实现</h2><h3 id="import-package-and-module"><a href="#import-package-and-module" class="headerlink" title="import package and module"></a>import package and module</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line">sys.path.append(<span class="string">"path to file storge d2lzh1981"</span>)</span><br><span class="line"><span class="keyword">import</span> d2lzh1981 <span class="keyword">as</span> d2l</span><br><span class="line"></span><br><span class="line">print(torch.__version__)</span><br><span class="line">print(torchvision.__version__)</span><br></pre></td></tr></table></figure>
<h3 id="获取数据"><a href="#获取数据" class="headerlink" title="获取数据"></a>获取数据</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">batch_size = <span class="number">256</span></span><br><span class="line">train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size)</span><br></pre></td></tr></table></figure>

<h3 id="模型参数初始化"><a href="#模型参数初始化" class="headerlink" title="模型参数初始化"></a>模型参数初始化</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># init module param </span></span><br><span class="line">num_inputs = <span class="number">784</span></span><br><span class="line">print(<span class="number">28</span>*<span class="number">28</span>)</span><br><span class="line">num_outputs = <span class="number">10</span></span><br><span class="line"></span><br><span class="line">W = torch.tensor(np.random.normal(<span class="number">0</span>, <span class="number">0.01</span>, (num_inputs, num_outputs)), dtype=torch.float)</span><br><span class="line">b = torch.zeros(num_outputs, dtype=torch.float)</span><br><span class="line">W.requires_grad_(requires_grad=<span class="literal">True</span>)</span><br><span class="line">b.requires_grad_(requires_grad=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<h3 id="Sofmax-定义"><a href="#Sofmax-定义" class="headerlink" title="Sofmax 定义"></a>Sofmax 定义</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># define softmax function</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">softmax</span><span class="params">(X)</span>:</span></span><br><span class="line">    X_exp = X.exp()</span><br><span class="line">    partition = X_exp.sum(dim=<span class="number">1</span>, keepdim=<span class="literal">True</span>)</span><br><span class="line">    <span class="comment"># print("X size is ", X_exp.size())</span></span><br><span class="line">    <span class="comment"># print("partition size is ", partition, partition.size())</span></span><br><span class="line">    <span class="keyword">return</span> X_exp / partition  <span class="comment"># 这里应用了广播机制</span></span><br></pre></td></tr></table></figure>

<h3 id="softmax-回归模型"><a href="#softmax-回归模型" class="headerlink" title="softmax 回归模型"></a>softmax 回归模型</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># define regression model</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">net</span><span class="params">(X)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> softmax(torch.mm(X.view((<span class="number">-1</span>, num_inputs)), W) + b)</span><br></pre></td></tr></table></figure>
<h3 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># define loss function</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">cross_entropy</span><span class="params">(y_hat, y)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> - torch.log(y_hat.gather(<span class="number">1</span>, y.view(<span class="number">-1</span>, <span class="number">1</span>)))</span><br></pre></td></tr></table></figure>
<h3 id="准确率"><a href="#准确率" class="headerlink" title="准确率"></a>准确率</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">accuracy</span><span class="params">(y_hat, y)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> (y_hat.argmax(dim=<span class="number">1</span>) == y).float().mean().item()</span><br></pre></td></tr></table></figure>
<h3 id="训练模型"><a href="#训练模型" class="headerlink" title="训练模型"></a>训练模型</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">num_epochs, lr = <span class="number">5</span>, <span class="number">0.1</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train_ch3</span><span class="params">(net, train_iter, test_iter, loss, num_epochs, batch_size,</span></span></span><br><span class="line"><span class="function"><span class="params">              params=None, lr=None, optimizer=None)</span>:</span></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> range(num_epochs):</span><br><span class="line">        train_l_sum, train_acc_sum, n = <span class="number">0.0</span>, <span class="number">0.0</span>, <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> X, y <span class="keyword">in</span> train_iter:</span><br><span class="line">            y_hat = net(X)</span><br><span class="line">            l = loss(y_hat, y).sum()</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 梯度清零</span></span><br><span class="line">            <span class="keyword">if</span> optimizer <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">                optimizer.zero_grad()</span><br><span class="line">            <span class="keyword">elif</span> params <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span> <span class="keyword">and</span> params[<span class="number">0</span>].grad <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">                <span class="keyword">for</span> param <span class="keyword">in</span> params:</span><br><span class="line">                    param.grad.data.zero_()</span><br><span class="line">            </span><br><span class="line">            l.backward()</span><br><span class="line">            <span class="keyword">if</span> optimizer <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">                d2l.sgd(params, lr, batch_size)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                optimizer.step() </span><br><span class="line">            </span><br><span class="line">            </span><br><span class="line">            train_l_sum += l.item()</span><br><span class="line">            train_acc_sum += (y_hat.argmax(dim=<span class="number">1</span>) == y).sum().item()</span><br><span class="line">            n += y.shape[<span class="number">0</span>]</span><br><span class="line">        test_acc = evaluate_accuracy(test_iter, net)</span><br><span class="line">        print(<span class="string">'epoch %d, loss %.4f, train acc %.3f, test acc %.3f'</span></span><br><span class="line">              % (epoch + <span class="number">1</span>, train_l_sum / n, train_acc_sum / n, test_acc))</span><br><span class="line"></span><br><span class="line">train_ch3(net, train_iter, test_iter, cross_entropy, num_epochs, batch_size, [W, b], lr)</span><br></pre></td></tr></table></figure>
<h3 id="模型预测"><a href="#模型预测" class="headerlink" title="模型预测"></a>模型预测</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">X, y = iter(test_iter).next()</span><br><span class="line"></span><br><span class="line">true_labels = d2l.get_fashion_mnist_labels(y.numpy())</span><br><span class="line">pred_labels = d2l.get_fashion_mnist_labels(net(X).argmax(dim=<span class="number">1</span>).numpy())</span><br><span class="line">titles = [true + <span class="string">'\n'</span> + pred <span class="keyword">for</span> true, pred <span class="keyword">in</span> zip(true_labels, pred_labels)]</span><br><span class="line"></span><br><span class="line">d2l.show_fashion_mnist(X[<span class="number">0</span>:<span class="number">9</span>], titles[<span class="number">0</span>:<span class="number">9</span>])</span><br></pre></td></tr></table></figure>
<hr>
<h2 id="Pytorch-改进"><a href="#Pytorch-改进" class="headerlink" title="Pytorch 改进"></a>Pytorch 改进</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># import package and module</span></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.nn <span class="keyword">import</span> init</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line">sys.path.append(<span class="string">"path to file storge d2lzh1981"</span>)</span><br><span class="line"><span class="keyword">import</span> d2lzh1981 <span class="keyword">as</span> d2l</span><br></pre></td></tr></table></figure>

<h3 id="初始化参数和获取数据"><a href="#初始化参数和获取数据" class="headerlink" title="初始化参数和获取数据"></a>初始化参数和获取数据</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># init param and get data</span></span><br><span class="line">batch_size = <span class="number">256</span></span><br><span class="line">train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size)</span><br></pre></td></tr></table></figure>
<h3 id="定义网络模型"><a href="#定义网络模型" class="headerlink" title="定义网络模型"></a>定义网络模型</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">num_inputs = <span class="number">784</span></span><br><span class="line">num_outputs = <span class="number">10</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">LinearNet</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, num_inputs, num_outputs)</span>:</span></span><br><span class="line">        super(LinearNet, self).__init__()</span><br><span class="line">        self.linear = nn.Linear(num_inputs, num_outputs)</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span> <span class="comment"># x 的形状: (batch, 1, 28, 28)</span></span><br><span class="line">        y = self.linear(x.view(x.shape[<span class="number">0</span>], <span class="number">-1</span>))</span><br><span class="line">        <span class="keyword">return</span> y</span><br><span class="line">    </span><br><span class="line"><span class="comment"># net = LinearNet(num_inputs, num_outputs)</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">FlattenLayer</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        super(FlattenLayer, self).__init__()</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span> <span class="comment"># x 的形状: (batch, *, *, ...)</span></span><br><span class="line">        <span class="keyword">return</span> x.view(x.shape[<span class="number">0</span>], <span class="number">-1</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> OrderedDict</span><br><span class="line">net = nn.Sequential(</span><br><span class="line">        <span class="comment"># FlattenLayer(),</span></span><br><span class="line">        <span class="comment"># LinearNet(num_inputs, num_outputs) </span></span><br><span class="line">        OrderedDict([</span><br><span class="line">           (<span class="string">'flatten'</span>, FlattenLayer()),</span><br><span class="line">           (<span class="string">'linear'</span>, nn.Linear(num_inputs, num_outputs))]) <span class="comment"># 或者写成我们自己定义的 LinearNet(num_inputs, num_outputs) 也可以</span></span><br><span class="line">        )</span><br></pre></td></tr></table></figure>

<h3 id="初始化模型参数"><a href="#初始化模型参数" class="headerlink" title="初始化模型参数"></a>初始化模型参数</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># init module param</span></span><br><span class="line">init.normal_(net.linear.weight, mean=<span class="number">0</span>, std=<span class="number">0.01</span>)</span><br><span class="line">init.constant_(net.linear.bias, val=<span class="number">0</span>)</span><br></pre></td></tr></table></figure>

<h3 id="损失函数-1"><a href="#损失函数-1" class="headerlink" title="损失函数"></a>损失函数</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">loss = nn.CrossEntropyLoss() <span class="comment"># 下面是他的函数原型</span></span><br><span class="line"><span class="comment"># class torch.nn.CrossEntropyLoss(weight=None, size_average=None, ignore_index=-100, reduce=None, reduction='mean')</span></span><br></pre></td></tr></table></figure>

<h3 id="优化函数"><a href="#优化函数" class="headerlink" title="优化函数"></a>优化函数</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">optimizer = torch.optim.SGD(net.parameters(), lr=<span class="number">0.1</span>) <span class="comment"># 下面是函数原型</span></span><br><span class="line"><span class="comment"># class torch.optim.SGD(params, lr=, momentum=0, dampening=0, weight_decay=0, nesterov=False)</span></span><br></pre></td></tr></table></figure>

<h3 id="训练"><a href="#训练" class="headerlink" title="训练"></a>训练</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">num_epochs = <span class="number">5</span></span><br><span class="line">d2l.train_ch3(net, train_iter, test_iter, loss, num_epochs, batch_size, <span class="literal">None</span>, <span class="literal">None</span>, optimizer)</span><br></pre></td></tr></table></figure>

<h3 id="训练结果分析"><a href="#训练结果分析" class="headerlink" title="训练结果分析"></a>训练结果分析</h3><p><img src="https://img-blog.csdnimg.cn/20200212213623439.png" alt="在这里插入图片描述"></p>
<blockquote>
<p>最开始：训练数据集上的准确率低于测试数据集上的准确率</p>
</blockquote>
<blockquote>
<blockquote>
<p>原因</p>
</blockquote>
<p>训练集上的准确率是在一个epoch的过程中计算得到的<br>测试集上的准确率是在一个epoch结束后计算得到的<br>Result: 后者的模型参数更优</p>
</blockquote>

        </div>

        
            <section class="post-copyright">
                
                    <p class="copyright-item">
                        <span>Author:</span>
                        <span>Rokosnake</span>
                    </p>
                
                
                
                    <p class="copyright-item">
                        <span>License:</span>
                        <span>Copyright (c) 2019 <a href="http://creativecommons.org/licenses/by-nc/4.0/" target="_blank" rel="noopener">CC-BY-NC-4.0</a> LICENSE</span>
                    </p>
                
                
                     <p class="copyright-item">
                         <span>Slogan:</span>
                         <span><strong>How to thought, there is what kind of life.</strong></span>
                     </p>
                

            </section>
        
        <section class="post-tags">
            <div>
                <span>Tag(s):</span>
                <span class="tag">
                    
                    
                        <a href="/tags/Softmax/"># Softmax</a>
                    
                        <a href="/tags/classify/"># classify</a>
                    
                        <a href="/tags/Fashion-MNIST/"># Fashion-MNIST</a>
                    
                        <a href="/tags/Computer-Vision/"># Computer Vision</a>
                    
                        
                </span>
            </div>
            <div>
                <a href="javascript:window.history.back();">back</a>
                <span>· </span>
                <a href="/">home</a>
            </div>
        </section>
        <section class="post-nav">
            
                <a class="prev" rel="prev" href="/2020/02/28/Multilayer%20Perceptron%20&%20Classify%20image/">Multilayer Perceptron & Classify image</a>
            
            
            <a class="next" rel="next" href="/2020/02/28/Design%20and%20Realization%20of%20Linear%20Regression/">Design and Realization of Linear Regression</a>
            
        </section>


    </article>
</div>

        </div>
        <footer id="footer" class="footer">
    <div class="copyright">
        <span>© Rokosnake | Powered by <a href="https://hexo.io" target="_blank">Hexo</a> & <a href="https://github.com/Siricee/hexo-theme-Chic" target="_blank">Chic</a></span>
    </div>
    <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span id="busuanzi_container_site_pv">本站总访问量<span id="busuanzi_value_site_pv"></span>次</span>
    <span class="post-meta-divider">|</span>
    <span id="busuanzi_container_site_uv">本站访客数<span id="busuanzi_value_site_uv"></span>人</span>
</footer>

    </div>
</body>
</html>
